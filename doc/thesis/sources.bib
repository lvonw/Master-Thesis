@preamble{"\providecommand{\NOOPSORT}[1]{}"}

@online{quelle,
    author = {Nachname, Vorname}, 
    title = {Name der Quelle},
    url = {http://www.website.com/pfad/zu/einem/bild.png},
    date = {2087-07-23},
    urldate = {2022-02-02}
}

@inbook{caterpillar,
    title = {The Very Hungry Caterpillar},
    publisher = {Puffin}, 
    place = {London, England},
    author = {Carle, Eric}, % wird als Eric Carle angezeigt, aber nach Carle sortiert
    edition = {1},
    year = {1994}, 
    chapter = {5},
    pages = {125–140},
    ISBN = {9780241003008},
    note = {\url{https://en.wikipedia.org/wiki/The_Very_Hungry_Caterpillar}}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@Article{join_study,
    AUTHOR = {Celesti, Antonio and Fazio, Maria and Villari, Massimo}, % Autoren mit and trennen
    TITLE = {A Study on Join Operations in MongoDB Preserving Collections Data Models for Future Internet Applications},
    JOURNAL = {Future Internet},
    VOLUME = {11},
    YEAR = {2019},
    NUMBER = {4},
    ARTICLE-NUMBER = {83},
    URL = {https://www.mdpi.com/1999-5903/11/4/83},
    ISSN = {1999-5903},
    DOI = {10.3390/fi11040083}
}

@article{https://doi.org/10.1111/j.1467-8659.2010.01827.x,
author = {Lagae, A. and Lefebvre, S. and Cook, R. and DeRose, T. and Drettakis, G. and Ebert, D.S. and Lewis, J.P. and Perlin, K. and Zwicker, M.},
title = {A Survey of Procedural Noise Functions},
journal = {Computer Graphics Forum},
volume = {29},
number = {8},
pages = {2579-2600},
keywords = {procedural noise function, noise, stochastic process, procedural, Perlin noise, wavelet noise, anisotropic noise, sparse convolution noise, Gabor noise, spot noise, surface noise, solid noise, anti-aliasing, filtering, stochastic modelling, procedural texture, procedural modelling, solid texture, texture synthesis, spectral analysis, power spectrum estimation, I.3.3 Computer Graphics: Picture/Image Generation—I.3.7 Computer Graphics: Three-Dimensional Graphics and Realism-Colour, shading, shadowing, and texture},
doi = {https://doi.org/10.1111/j.1467-8659.2010.01827.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8659.2010.01827.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2010.01827.x},
abstract = {Abstract Procedural noise functions are widely used in computer graphics, from off-line rendering in movie production to interactive video games. The ability to add complex and intricate details at low memory and authoring cost is one of its main attractions. This survey is motivated by the inherent importance of noise in graphics, the widespread use of noise in industry and the fact that many recent research developments justify the need for an up-to-date survey. Our goal is to provide both a valuable entry point into the field of procedural noise functions, as well as a comprehensive view of the field to the informed reader. In this report, we cover procedural noise functions in all their aspects. We outline recent advances in research on this topic, discussing and comparing recent and well-established methods. We first formally define procedural noise functions based on stochastic processes and then classify and review existing procedural noise functions. We discuss how procedural noise functions are used for modelling and how they are applied to surfaces. We then introduce analysis tools and apply them to evaluate and compare the major approaches to noise generation. We finally identify several directions for future work.},
year = {2010}
}

@article{perlin1985image,
  title={An image synthesizer},
  author={Perlin, Ken},
  journal={ACM Siggraph Computer Graphics},
  volume={19},
  number={3},
  pages={287--296},
  year={1985},
  publisher={ACM New York, NY, USA}
}

@inproceedings{rombach2022high,
  title={High-resolution image synthesis with latent diffusion models},
  author={Rombach, Robin and Blattmann, Andreas and Lorenz, Dominik and Esser, Patrick and Ommer, Bj{\"o}rn},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10684--10695},
  year={2022}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={4195--4205},
  year={2023}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@misc{vaswani2023attentionneed,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2023},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1706.03762}, 
}

@misc{goodfellow2014generativeadversarialnetworks,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1406.2661}, 
}

@misc{thanhtung2020catastrophicforgettingmodecollapse,
      title={On Catastrophic Forgetting and Mode Collapse in Generative Adversarial Networks}, 
      author={Hoang Thanh-Tung and Truyen Tran},
      year={2020},
      eprint={1807.04015},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1807.04015}, 
}

@inproceedings{larsen2016autoencoding,
  title={Autoencoding beyond pixels using a learned similarity metric},
  author={Larsen, Anders Boesen Lindbo and S{\o}nderby, S{\o}ren Kaae and Larochelle, Hugo and Winther, Ole},
  booktitle={International conference on machine learning},
  pages={1558--1566},
  year={2016},
  organization={PMLR}
}

@book{Deisenroth2020,
  added-at = {2019-10-12T23:39:32.000+0200},
  author = {Deisenroth, Marc Peter and Faisal, A. Aldo and Ong, Cheng Soon},
  biburl = {https://www.bibsonomy.org/bibtex/271e556439bb49b11e015aa4c0d9cb785/lopusz_kdd},
  description = {Mathematics for Machine Learning: Marc Peter Deisenroth, A. Aldo Faisal, Cheng Soon Ong: 9781108455145: Amazon.com: Books},
  interhash = {876f4a593e888f3257674a89d7456f25},
  intrahash = {71e556439bb49b11e015aa4c0d9cb785},
  keywords = {general_machine_learning},
  publisher = {Cambridge University Press},
  timestamp = {2019-10-12T23:43:51.000+0200},
  title = {Mathematics for Machine Learning},
  year = 2020
}

@article{JMLR:v6:hyvarinen05a,
  author  = {Aapo Hyv{{\"a}}rinen},
  title   = {Estimation of Non-Normalized Statistical Models by Score Matching},
  journal = {Journal of Machine Learning Research},
  year    = {2005},
  volume  = {6},
  number  = {24},
  pages   = {695--709},
  url     = {http://jmlr.org/papers/v6/hyvarinen05a.html}
}

@InProceedings{pmlr-v37-sohl-dickstein15,
  title = 	 {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},
  author = 	 {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2256--2265},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/sohl-dickstein15.html},
  abstract = 	 {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}
}

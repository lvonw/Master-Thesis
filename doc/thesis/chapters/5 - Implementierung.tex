\chapter{Implementierung}
\label{ch:Implementierung}

Dieses Kapitel widmet sich den relevanten Details der Implementierung der in Abschnitt \ref{ch:Methodik} konzipierten Generierungsprozesse sowie den dafür nötigen generativen Modellen. Die Implementierung wurde auf Basis von PyTorch vorgenommen, alle in dieser Arbeit genutzten Modellarchitekturen wurden, unter der Orientierung an den von den Autoren des jeweils betreffenden Ansatzes öffentlich gemachten Erstumsetzungen, selbständig implementiert. Die betreffenden Vorbilder werden hier bei der Erläuterung der Umsetzung referenziert. \\
Die hier dargestellten Quellcode-Ausschnitte der Implementierung sind zur besseren Lesbarkeit und zur Untersützung des Verständnisses stark gekürzt und stellenweise vereinfacht. Gegebenenfalls wurden Symbole und Funktionen umbenannt, um an die in dieser Arbeit verwendete Terminologie anzuknüpfen. Semantisch bleibt der Inhalt durch diese Anpassungen allerdings unverändert.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \section {Grundlegende Programmstruktur}

% asdas

% \section {Konfiguration}

% asdas

\section {Datenframework}

Bei der Implementierung des Datenframeworks war insbesondere die Datensatzagnostik der zentrale Leitgedanke. Es sollte einfach konfigurierbar sein, welche Daten genutzt werden sollten und welche nicht, sowohl für die \ac{DEM}s als auch die Kontrollsignale. Zusätlich sollten die Augmentierungen frei konfigurierbar sein, um gegebenenfalls welche hinzufügen zu können. \\
Zu diesem Zweck wurde die Hauptroutine des Frameworks, welche zum Laden und zur Laufzeitverarbeitung der Daten zur Trainingszeit dient, wie in Abbildung \ref{fig:Data_runtime} dargestellt implementiert. Hierbei werden die bereits in Kapitel \ref{ch:Datenaufbereitung} geschilderten Schritte durchlaufen. Auffallend ist hierbei zusätzlich die Nutzung eines Caches, durch welchen die geladenen Daten im Arbeitsspeicher gehalten werden, was die Laufzeiteffizienz deutlich erhöht.
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def __getitem__(self, index):
    cache       = GeoDatasetCache()
    file = self.dem_list[index]
    dem_tensor, dem_shape, dataset = self.load(file)  
    # Ermittle die Geokoordinaten aus dem DEM
    (tl_geo, br_geo), dem_geo_transform = (
        self.get_geo_coordinates(dataset, dem_shape))    
    cache.geo_coordinates   = (tl_geo, br_geo)
    cache.geo_transform     = dem_geo_transform
    # Ordne die jeweiligen Labelausschnitte dem DEM zu 
    for cache in self.label_sets:
        label, label_frame = self.__load_label(cache, 
            tl_geo, br_geo)
        cache.label_tensor = label
        cache.label_frames.append(label_data_frame)
    label_frames = cache.label_frames
    # Wende die Datenaugmentierungs Transformationen an 
    data_entry, label_frames = self.aug_transforms(
        data_entry, label_frames)
    # Ermittle die Klassen aus den Ausschnitten 
    labels = []
    for _, label_frame in enumerate(label_frames):
        label = torch.median(label_frame)
    return data_entry, label
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Laufzeitverarbeitung der DEM- und Klassendaten}
    \label{fig:Data_runtime}
\end{figure} \\
Sofern der Cache genutzt werden soll, kann dieser sowohl zur Trainingszeit als auch vorher gefüllt werden. Für die genaue Implementierung des Caches wurde eine Python distributed List verwendet, welche über den Itemindex angesprochen wird. Dies erlaubt es, mehrere Threads effizienter beim Laden der Daten zu nutzen, was beim Training einen deutlichen Performanzunterschied macht, vor allem auf schwächeren Maschinen. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section {Variational Autoencoder}

Wie spezifiziert handelt es sich bei der Implementierung des \ac{VAE} um ein VAE-GAN mit einer zusätzlichen visuellen Qualitätsmetrik in Form von \ac{LPIPS}. Für die Implementierung ist hierbei die sich als Standard etablierte KL-reg. Variante von Rombach et al.\footnote{
    Vgl. Rombach et al.: Latent Diffusion Models, S. 3f.
    \cite{rombach2022high}
} maßgebend. Encoder und Decoder werden jeweils durch den Kompressions- und Expansionsarm eines U-Nets umgesetzt, auf die Skipverbindungen wird dabei verzichtet. Für den Diskriminator wird ein einfaches PatchGAN vorgesehen, welches die Diskriminierungs-Entscheidung für einzelne Patches anstelle des Gesamten Bildes vornimmt\footnote{
    Vgl. Isola et al.: Image-to-Image Translation with Conditional GANs, S. 3f.
    \cite{isola2018imagetoimagetranslationconditionaladversarial}
}. \\
Für die \ac{LPIPS} Qualitätsmetrik wurde die ursprüngliche Implementierung von Zhang et al. übernommen\footnote{
    Zhang et al.: The Unreasonable Effectiveness of Deep Features as a Perceptual Metric
    \cite{zhang2018unreasonableeffectivenessdeepfeatures}
}, die Architektur muss dabei exakt dieselbe sein, da ein vortrainiertes Netz verwendet werden muss. Eine Detailanpassung der Umsetzung dabei ist allerdings, dass nun auch einkanälige Bilder verarbeitet werden können, wofür der eine Kanal verdreifacht wird, um auf die erforderlichen drei Kanäle zu kommen. \\
Diese grundlegenden Komponenten des VAE-GAN werden in Abbildung \ref{fig:vae_arch} noch einmal strukturell dargelegt. 
\begin{figure}[htbp]
    \centering
    \subfloat{%
        \includegraphics[width=0.65\textwidth]{images/implementation/VAE.pdf}
    }
    \caption{Komponenten des VAE-GAN}
    \label{fig:vae_arch}
\end{figure}
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def encode(self, x):
    x = self.encoder(x)
    mu, log_var = torch.chunk(x, 2, dim=1) 
    sigma   = log_var.exp().sqrt()
    # Reparametrisierung
    latents = mu + sigma * torch.randn(mu.shape)
    return LatentEncoding(latents, mu, log_var)

def decode(self, z):
    return self.decoder(z)

def forward(self, x):
    latent_encoding = self.encode(x) 
    z = latent_encoding.latents
    recon = self.decode(z)
    return recon, latent_encoding
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Encoding und Decoding Funktionen des VAE-GAN}
    \label{fig:vae_forward}
\end{figure} \\
Der Quellcode in Abbildung \ref{fig:vae_forward} zeigt die jeweiligen Operationen zur Ver- und Entschlüsselung, welche parallel zu jedem normalen \ac{VAE} verläuft, wodurch noch einmal verdeutlicht wird, dass der \ac{GAN}-Anteil des VAE-GAN lediglich beim Training für die visuelle Verbesserung der Ergebnisse verwendet wird. \\
Hierauf aufbauend folgt in Abbildung \ref{fig:vae_training} die Implementierung eines Trainingsschrittes, welche den Verlust ermittelt. Diese setzt das bereits in Unterabschnitt \ref{subsubsec:vae_optim} definierte Trainingsobjektiv um. Besonders hervorzuheben ist bei dieser Implementierung zum einen die Zweiteilung des Prozesses, die zeigt, dass Diskriminator und \ac{VAE} seperat traininert werden. Dies liegt an der zugrundeliegenden Implementierung des Trainings in PyTorch. Hier wird beim Training ein Graph der getätigten Verarbeitungsschritte aufgebaut, welcher bei der Backpropagation durchlaufen wird. Dies würde bei dem Minimax-Ziel des VAE-GAN zu Problemen führen, würde man beide gleichzeitig trainieren, da die Gewichte der Encoder und Decoder nur bei einem der beiden Optimierungsziele verändert werden sollen. \\
Letztlich ist die Rolle des Diskriminators im \ac{VAE} Training gut zu erkennen, hier wird durch \texttt{-torch.mean(self.disc(recons))} angegeben, dass hier eine möglichst hohe Aktivierung erzielt werden soll, also eine Einstufung als reale Daten. 
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def training_step(self, inputs, step_idx, optim_idx):
    recons, latents = self(inputs)
    # Diskriminator Training 
    if self.use_discriminator and optim_idx == 1:
        return disc_loss(self.disc(inputs), 
            self.disc(recons))
    # VAE Training
    recon_loss  = torch.abs(recons - inputs)
    kl_d        = self.normal_kl_d(latents)      
    if self.use_perceptual_loss:   
        percep_loss = self.percep_loss(inputs, recons)
    if self.use_discriminator 
        and step_idx >= self.disc_warmup:    
        disc_loss = -torch.mean(self.disc(recons))
    return recon_loss + self.weight_kl * kl_d 
        + self.weight_d * disc_loss 
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Trainingsschrittroutine des VAE-GAN}
    \label{fig:vae_training}
\end{figure} \\
Zusätzlich zu diesen verwendeten Techniken werden auch die von Podell et al.\footnote{
    Podell et al.: SDXL, S. 7 
    \cite{podell2023sdxlimprovinglatentdiffusion}
} vorgeschlagene Verbesserung des \ac{VAE}s durch Nutzung eines \ac{EMA} implementiert, welche neu gelernte Informationen nur graduell in ein sogenanntes \ac{EMA}-Modell überführt, welches somit resistenter gegen Ausreißer und temporäre Fehlentwicklungen beim Training ist\footnote{
    Vgl. Kingma, Ba: ADAM, S. 3ff. 
    \cite{kingma2017adammethodstochasticoptimization}
}. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section {Latentes Diffusionsmodel}

Das \ac{LDM} stellt das Herzstück dieser Arbeit dar und entsprechend viel Acht muss bei der Implementierung hiervon gegeben werden. \\ 
Die Trainingsschrittfunktion des \ac{LDM}s, siehe Abbildung \ref{fig:ldm_training}, stellt im Grunde den für \ac{DDPM} üblichen Trainingsalgorithmus dar. Jedoch sind hierbei klar die bereits angesprochenen Verbesserungen zu erkennen. Zuerst fällt die Überführung der Daten in den latenten Raum auf, in welchem ebenfalls die Rauschvorhersage getroffen wird. Darauf folgend ist klar der Prozess der \ac{CFG} zu erkennen bei welcher mit einer definierten Wahrscheinlichkeit die Kontrollsignale annulliert werden. Abschließend wird das verbesserte Trainingsziel $L_\text{hybrid}$ eins zu eins umgesetzt.
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def training_step(self, x, labels):
    x = self.latent_model.encode(x).latents
    # Vorwaertsprozess bei Zeitschritt t
    t = self.__sample_from_timesteps(self.training_T)
    noised_images, noise = self.__add_noise(x, t)
    # Classifier Free Guidance
    if self.use_classifier_free_guidance: 
        mask = torch.rand() < self.no_class_probability
        labels = torch.where(mask, const.NULL_LABEL, 
            labels)   
    # Rauschvorhersage
    x_t = self.model(noised_images, labels, t)
    return l_hybrid(noise, x, noised_images, x_t, t)
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Trainingsschrittroutine des LDM}
    \label{fig:ldm_training}
\end{figure} \\
Der Sampling-, beziehungsweise Rückwärtsprozess, zu sehen in Abbildung \ref{fig:ldm_sample}, entspricht ebenfalls grundlegend der für \ac{DDPM}s üblichen Form. Allerdings werden hier deutlich mehr Anpassungen getroffen, welche für die Umsetzung der definierten Generierungsprozesse erforderlich sind, als es noch beim Training der Fall war. \\
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def sample(self, ctrl_signal, sketch, i2i_strength,
    mask, masked_input):
    starting_offset = 0
    if sketch is None:
        x = torch.randn()
    # Skizzensteuerung
    else:
        start_t = i2i_strength * self.sample_T
        timesteps = self.sample_steps[start_t]
        x   = self.latent_model.encode(sketch).latents
        x, _= self.__add_noise(x, timesteps)
    # Masking 
    if mask is not None:
        masked_input = self.latent_model
            .encode(masked_input).latents
        mask = resize_to_latent_size(mask)
        inverted_mask = 1 - mask
    for t in tqdm(self.sample_steps[start_t:])  
        x_t = self.model(x, ctrl_signal, t)
        # Classifier Free Guidance 
        if self.use_classifier_free_guidance:       
            null_labels = const.NULL_LABEL
            uncon_x_t  = self.model(x, null_labels, t)
            x_t = lerp(uncon_x_t, x_t, self.cfg_w)
        # Entrauschen
        x = self.__predict_mean_variance(t, x, x_t)        
        # Wende Maske an
        if mask is not None:
            noised_mask, _ = self.__add_noise(
                masked_input, t) 
            x = noised_mask * mask + x * inverted_mask
        return self.latent_model.decode(x)
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Samplefunktion des LDM}
    \label{fig:ldm_sample}
\end{figure} \\
Zuerst wird zwischen Generierung mit oder ohne Skizze unterschieden. Für den Fall, dass eine Skizze angegeben wurde, muss der entsprechende Startzeitschritt gesetzt werden. Zusätzlich muss in diesem Fall die Skizze auf ihre latente Repräsentation abgebildet und anschließend entsprechend $t$ verrauscht werden. Andernfalls muss lediglich ein Rauschbild einer Standardnormalverteilung entnommen sowie der Startzeitschritt auf $T$ gesetzt werden. \\ 
Zusätzlich kann auch eine Maske definiert werden, was erfordert, dass das zu maskierende Bild ebenfalls durch den \ac{VAE} komprimiert wird. Die Maske selbst wird entsprechend der Dimensionalität der latenten Repräsentationen verkleinert, um später angewendet werden zu können. Ihre Gegenmaske wird aus Effizienzgründen ebenfalls an dieser Stelle einmal erstellt. \\
Hiernach folgt die eigentliche Schleife des Rückwärtsprozesses beginnend bei dem definierten Startzeitschritt. Die \ac{CFG} wird in diesem Ausschnitt durch zwei separate Modellaufrufe umgesetzt, tatsächlich kann dies aber auch in einem einzigen Durchlauf bewerkstelligt werden. Dies ist zwar theoretisch laufzeiteffizienter, kann aber durch die erhöhten Grafikspeicher-Anforderungen auf schwächeren \ac{GPU}s in der Praxis langsamer sein, als zwei separate Samplingprozesse. \\
Anschließend wird nach dem Entrauschen des aktuellen $x_t$ noch die Maske angewendet, bei welcher entsprechend den $\alpha$ Werten des Maskenbildes und der Gegenmaske die jeweiligen Bereiche des Maskenbildes übernommen werden. \\
Abgeschlossen wird der Prozess durch die Entschlüsselung der latenten Repräsentation des Samples zurück in den Bildraum. \\
Das in diesen Ausschnitten verwendete \texttt{self.model} bezieht sich hierbei auf ein reguläres \ac{DM}. Jedoch wird in dieser Arbeit, da zwei unterschiedliche Architekturen für das DM getestet werden, zunächst eine Abstraktion der DM-Funktionalität eingeführt. Diese ist agnostisch gegenüber der gewählten Architektur und stellt somit eine Wrapper-Klasse dar. Die \texttt{forward} Funktion dieses Wrappers ist in Abbildung \ref{fig:DM_forward} dargestellt. Diese übernimmt das Embedding des Zeitschrittes sowie der Kontrollsignale und leitet diese anschließend an die gewählte konkrete Implementierung des \ac{DM}s weiter. 
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def forward(self, x, ctrl_signal, t):
    timestep = self.__get_time_embedding(t, 
        self.embedding_size)
    timestep = self.time_embedding(t)
    ctrl_signal = self.label_embedding(ctrl_signal)
    return self.model(x, ctrl_signal, t)
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Diffusionsmodell-Wrapper Inferenzfunktion}
    \label{fig:DM_forward}
\end{figure} \\
Dieses Zusammenspiel der einzelnen Komponenten ist zur Veranschaulichung noch einmal in Abbildung \ref{fig:LDM_arch} dargestellt.
\begin{figure}[htbp]
    \centering
    \subfloat{%
        \includegraphics[width=0.50\textwidth]{images/implementation/LDM.pdf}
    }
    \caption{Komponenten des \ac{LDM}}
    \label{fig:LDM_arch}
\end{figure}
Die erste Architektur ist dabei das U-Net, von welchem die Samplingfunktion in Abbildung \ref{fig:UNET_forward} dargestellt ist. Die Implementierung ist hierbei genau der üblichen entsprechend. Zuerst wird der Kompressionsarm durchlaufen, wobei Kopien der jeweils relevanten Schritte erstellt werden, welche im Expansionsarm an die zugehörigen Aktivierungen konkatteniert werden.  
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def unet_forward(self, x, ctrl_signal, t):
    skip_connections = []
    # Adjusting Input
    x = self.input_conv(x)
    skip_connections.append(x)
    # Encoding
    for layers in self.encoder:
        x = layers(x, ctrl_signal, t)
        skip_connections.append(x)
    # Bottlenecki
    x = self.bottleneck(x, ctrl_signal, t)
    # Decoding
    for layers in self.decoder:
        x = torch.cat((x, skip_connections.pop())) 
        x = layers(x, ctrl_signal, t)
    return self.output_conv(x)
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Inferenzfunktion des U-Nets}
    \label{fig:UNET_forward}
\end{figure} \\
Auch die Implementierung des \ac{DiT}s entspricht der Vorlage, welche von Peebles und Xi\footnote{
    Vgl. Peebles, Xie: Diffusion Transformers
    \cite{peebles2023scalable}
} vorgestellt wurde. Ihre Umsetzung für diese Arbeit wird in Abbildung \ref{fig:DiT_forward} umrissen. Zunächst wird hierbei das Eingabebild in Patches aufgeteilt, welche anschließend mit dem Positionsembedding versehen werden. Hierauf folgt der Durchlauf aller DiT-Blöcke und zuguterletzt werden die Patches wieder zusammengefügt. 
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def dit_forward(self, x, ctrl_signal, t):
    x = self.patchify(x)
    x = self.positional_encoding(x)
    ctrl_signal += t
    # DiT Bloecke
    for dit_block in self.dit_blocks:
        x = dit_block(x, ctrl_signal)
    # Zusammensetzen der Patches
    x = self.output_layer(x)
    return self.__unpatchify(x)
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Inferenzfunktion des DiT}
    \label{fig:DiT_forward}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section {Terraingenerierung}

Vieles der für die Implentierung der definierten Generierungsprozesse notwendigen Logik ist bereits durch die Samplefunktion des \ac{LDM}s umgesetzt. Jedoch erfordern die einzelnen Bereiche noch weitere Schritte, um die nötigen Parameter zu erzeugen, die Samples zu vollenden und die Generierung sinnvoll zu organisieren. Hierzu werden die einzelnen Stationen im Folgenden betrachtet.


\subsection {Ungesteuert}

\begin{figure}[htbp]
    \centering
    \subfloat{%
        \includegraphics[width=0.9\textwidth]{images/implementation/uncontrolled.pdf}
    }
    \caption{Schematische Darstellung des Syntheseprozesses im \ac{LDM} bei der ungesteuerten Generierung}
    \label{fig:unguided}
\end{figure}
Die ungesteuerte Generierung ist ein sehr simpler Anwendungsfall wie sich an dem Auszug in Abbildung \ref{fig:gen_unguided} erkennen lässt. Es handelt sich lediglich um den wiederholten normalen Aufruf der Samplingfunktion des \ac{LDM}s welche bereits behandelt wurde und im Ablauf noch einmal gesondert in Abbildung \ref{fig:unguided} abgebildet ist. Es werden an dieser Stelle keinerlei weitere Vorkehrungen für diesen Generierungsprozess vorgenommen.   
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def __generate_unguided(model, labels, n, iterations):
    samples = []
    for i in range(iterations):
        label = labels[i % len(labels)]
        sample = model.sample(label, n)
        samples.append(sample)
    return samples
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Einfacher Generierungsprozess ohne Skizze}
    \label{fig:gen_unguided}
\end{figure}

\subsection {Skizzenbasiert}

\begin{figure}[htbp]
    \centering
    \subfloat{%
        \includegraphics[width=0.95\textwidth]{images/implementation/sketch.pdf}
    }
    \caption{Schematische Darstellung des Syntheseprozesses im \ac{LDM} bei der skizzenbasierten Generierung}
    \label{fig:sketch}
\end{figure}
Dieser Prozess erfordert mehr eigene Logik als der ungesteuerte. Das Meiste der Funktionalität wird allerdings auch in diesem Fall von der Umsetzung des Samplings im \ac{LDM} durchgeführt, sie ist für diesen Prozess in Abbildung \ref{fig:sketch} festgehalten. \\
Neu hierbei ist nun die Definition der Skizze. Diese kann entweder über einen Pfad definiert werden, in welchem Fall sie geladen und anschließend in den Wertebereich $[-1,1]$ abgebildet wird, oder aber über Perlinrauschen. Dabei wird über einen Generator, welcher den normalen Perlin-Algorthmus umsetzt, das Rauschbild erzeugt. Die Angabe der Koordinate \texttt{(0, 0)} bezieht sich hierbei auf die Position des Rauschbildes im gesamten Rauschfeld. Dies spielt an dieser Stelle noch keine Rolle, dementsprechend wurde die Koordinate hier konstant festgelegt. Von dieser Anpassung abgesehen ist die Implementierung parallel zur ungesteuerten Generierung.
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def __generate_sketch(model, labels, n, iterations,
    cfg_weight, sketch_path):
    
    samples = []
    if use_perlin:
        sketch = perlin.generate_image((0, 0))
    else:
        input_array = np.array(Image.open(sketch_path))
        sketch = get_normalized_array(input_array)
    for i in range(iterations):
        label = labels[i % len(labels)]
        sample = model.sample(label, n, sketch,
            i2i_strength  = weight)
        samples.append(sample)
    return samples
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Skizzenbasierte Generierung}
    \label{fig:gen_sketch}
\end{figure}

\subsection {Unendlich}

\begin{figure}[htbp]
    \centering
    \subfloat{%
        \includegraphics[width=0.95\textwidth]{images/implementation/infinite.pdf}
    }
    \caption{Schematische Darstellung des Syntheseprozesses im \ac{LDM} bei der unendlichen Generierung}
    \label{fig:infinite}
\end{figure}
Die unendliche Generierung erfordert die meiste eigene Logik für die Umsetzung des Gitternetzes sowie der Masken. Die Generierung basiert hier auf den einzelnen Zellen des Gitters, auch Chunk oder Patch genannt. Diese Generierung wird im Ganzen durch die in Abbildung \ref{fig:gen_infinite} gezeigte Funktion verarbeitet. Hierbei werden zunächst das Gitter sowie ein Alphavektor initialisiert. Dabei sind die Längen der zu maskierenden Bereiche der benachbarten Zellen welche durch eine Konstante angegeben sind zu beachten. Die einzelnen Alphavektoren werden durch die im weiteren Verlauf Alphafunktionen genannten Funktionen definiert. Konkret sind in dieser Arbeit die vier folgenden Alphafunktionen umgesetzt: 
\begin{itemize}
    \item \textit{Konstant}: $\alpha(x) = 1$
    \item \textit{Linear}: $\alpha(x) = 1 - x$
    \item \textit{Exponentiell}: $\alpha(x) = 2^{-7x}$
    \item \textit{Sinus}: $\alpha(x) = -\sin(\frac{x\pi}{2}) + 1$
\end{itemize}
Dabei gilt jeweils, dass $x \in [0,1]$. $x$ ist die relative Position eines Pixels in dem maskierten Randbereich der Länge dieser Überlappung. Ein $\alpha$ von eins bedeutet im Übrigen, dass hier das Maskenbild vollständig übernommen wird - also eine maximale Maskierung. Bei allen anderen Werten wird anhand dieses $\alpha$ linear zwischen generiertem Sample und Maskenbild interpoliert. \\
Hierauf folgt die Iteration über alle Zellen des Gitters wobei die einzelnen Generationschritte des Chunks ausgelagert werden. Abschließend wird durch das Gitter das finale Bild zusammengefügt. Hierbei ist wichtig, dass die einzelnen Chunks anhand der Generierungsreihenfolge in das Zielbild eingefügt werden, damit die überlappenden Bereiche bündig in einander übergehen. Dies liegt daran, dass natürlich nur die späteren Samples Kenntnis über die bereits generierten Nachbarn haben können, somit also erst bei ihrer Generierung die flüssigen Übergänge der Randbereiche entstehen. 
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def __generate_infinite(model, labels, grid_x, grid_y,
    cfg_weight, sketch, alpha)
    # Erstelle das Gitternetz
    grid = GenerationGrid(const.OVERLAP_SIZE)
    alpha = __get_alpha(const.OVERLAP_SIZE, alpha)
    amount_cells = grid_x * grid_y
    # Generiere alle Gitterzellen der Reihe nach
    for i in range(amount_cells):
        coord = (i % grid_x, i // grid_x)
        label = labels[cell_idx % len(labels)]
        __generate_chunk(model, grid, coord, sketch
            cfg_weight, alpha, label)
    return grid.stitch_image()
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Unendliche Generierung}
    \label{fig:gen_infinite}
\end{figure} \\
Die einzelnen Chunks werden anhand der Funktion in Abbildung \ref{fig:gen_chunk} synthetisiert. Diese besteht zuerst aus der Erstellung des Maskenbildes und der Maske anhand der bereits generierten benachbarten Zellen und dem Alphavektor. Die hieraus entstehende Maske hat die gleichen Dimensionen wie die Bilder und besteht an ihren Rändern aus den jeweils ausgerichteten Alphavektoren. Das Maskenbild ist lediglich eine Zusammenfügung der Ränder der benachbarten Zellen, wobei der Zwischenraum, also der unmaskierte Bereich, mit einer Skizze aufgefüllt werden kann. Dies soll die Abbildung des Maskenbildes auf die latente Repräsentation unterstützen, da es den sonst sehr unnatürlichen leeren Raum durch plausiblere Daten auffüllt. \\
Der Prozess der Synthese für jeden Chunk wird hierfür in Abbildung \ref{fig:infinite} veranschaulicht.
Nach der Synthese des Samples wird dieses ein letztes Mal mit dem Maskenbild interpoliert. Allerdings, geschieht dies nun im Bildbereich anstelle des latenten Raumes. Dies soll durch die Rekonstruktion an den Rändern eventuell entstandene Artefakte entfernen, um die Bündigkeit zu wahren. Abschließend wird der Chunk in das Gitter eingefügt, damit in der nächsten Iteration darauf aufgebaut werden kann.
\begin{figure}[htbp]
\begin{lstlisting}[language=python]
def __generate_chunk(model, grid, coordinate, sketch
    cfg_weight, alpha, label):

    mask, masked_image = grid.get_mask(coordinate, 
        alpha, sketch)
    samples = model.sample(label, sketch, cfg_weight,
        mask, masked_image)
    final_image = grid.create_final_image(samples, 
        masked_image, mask)
    grid.insert(final_image, coordinate)
\end{lstlisting}
    \captionsetup{type=figure}
    \captionof{figure}{Generierung einer einzelnen Gitterzelle}
    \label{fig:gen_chunk}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section {Visualisierung}

Die Visualisierung wurde mittels der Blender Python API umgesetzt. Der Algorithmus ist dabei verhältnismäßig naiv. Es wird lediglich ein Shader aufgebaut, welcher durch das \ac{DEM} definierte Mesh anhand der Z-Koordinate der Vertices sowie dem Winkel der Normalen bestimmt wird. Die jeweils korrespondierenden Materialien und Höhen- beziehungsweise Winkelwerte werden dabei in einer einfachen JSON Struktur definiert.
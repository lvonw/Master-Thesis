VAE_1x64x64_4x16x16:
  name: "VAE_1x64x64_4x16x16"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 64
  data_resolution_y: 64

  latent_num_channels: 4
  latent_resolution_x: 16
  latent_resolution_y: 16
  
  # Defines the structure of the vae
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 32
    dropout: 0.0
    non_linearity: SiLU
    # Each channel multiplier denotes a resolution block
    # One block will be added with the last channel multiplier for the 
    # bottle neck
    channel_multipliers:
    - 1
    - 2
    - 4

    # resolution blocks at which we should use attention
    attention_resolutions: []

  # Training parameters
  training:
    learning_rate: 0.0001


VAE_1x32x32_4x8x8:
  name: "VAE_1x32x32_4x8x8"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 4
  latent_resolution_x: 8
  latent_resolution_y: 8
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 32
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4

    attention_resolutions: []

  training:
    learning_rate: 0.0001


VAE_1x32x32_4x8x8_2:
  name: "VAE_1x32x32_4x8x8_2"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 4
  latent_resolution_x: 8
  latent_resolution_y: 8
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 128
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4

    attention_resolutions: []

  training:
    learning_rate: 0.0001


VAE_1x16x16_4x4x4:
  name: "VAE_1x16x16_4x4x4"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 16
  data_resolution_y: 16

  latent_num_channels: 4
  latent_resolution_x: 4
  latent_resolution_y: 4
  
  architecture:
    ResNet_blocks_per_layer: 1
    starting_channels: 32
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4
    use_attention: True
    attention_resolutions: []

  training:
    learning_rate: 0.0001


VAE_1x16x16_4x8x8:
  name: "VAE_1x16x16_4x8x8"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 16
  data_resolution_y: 16

  latent_num_channels: 4
  latent_resolution_x: 8
  latent_resolution_y: 8
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2

    attention_resolutions: []

  training:
    learning_rate: 0.0001



VAE_1x16x16_4x4x4_2:
  name: "VAE_1x16x16_4x4x4_2"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 16
  data_resolution_y: 16

  latent_num_channels: 4
  latent_resolution_x: 4
  latent_resolution_y: 4
  
  architecture:
    ResNet_blocks_per_layer: 1
    starting_channels: 32
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4
    use_attention: False
    attention_resolutions: []

  training:
    learning_rate: 0.0001

VAE_1x16x16_4x4x4_3:
  name: "VAE_1x16x16_4x4x4_3"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 16
  data_resolution_y: 16

  latent_num_channels: 4
  latent_resolution_x: 4
  latent_resolution_y: 4
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4
    use_attention: True
    attention_resolutions: []

  training:
    learning_rate: 0.0001

VAE_1x16x16_4x4x4_4:
  name: "VAE_1x16x16_4x4x4_4"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 16
  data_resolution_y: 16

  latent_num_channels: 4
  latent_resolution_x: 4
  latent_resolution_y: 4
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4
    use_attention: True
    attention_resolutions: []

  training:
    learning_rate: 0.0001

VAE_1x16x16_4x4x4_5:
  name: "VAE_1x16x16_4x4x4_5"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 16
  data_resolution_y: 16

  latent_num_channels: 16
  latent_resolution_x: 4
  latent_resolution_y: 4
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 2
    - 4
    use_attention: True
    attention_resolutions: []

  training:
    learning_rate: 0.0001


VAE_MNIST:
  name: "VAE_MNIST"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 28
  data_resolution_y: 28

  latent_num_channels: 4
  latent_resolution_x: 7
  latent_resolution_y: 7
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    use_attention: true
    attention_resolutions: []

  training:
    learning_rate: 0.0001


VAE_1x16x16_4x4x4_6:
  name: "VAE_1x16x16_4x4x4_6"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 16
  latent_resolution_x: 8
  latent_resolution_y: 8
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
  
    use_attention: true
    attention_resolutions: []

  training:
    learning_rate: 0.0001



VAE_1x16x16_4x4x4_7:
  name: "VAE_1x16x16_4x4x4_7"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 16
  latent_resolution_x: 8
  latent_resolution_y: 8
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4

    use_attention: true
    attention_resolutions: []

  training:
    learning_rate: 0.0001

VAE_1x16x16_4x4x4_8:
  name: "VAE_1x16x16_4x4x4_8"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 16
  latent_resolution_x: 8
  latent_resolution_y: 8

  beta: 0.000001
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2

    use_attention: true
    attention_resolutions: []

  training:
    learning_rate: 0.0001


VAE_1x16x16_4x4x4_biggerbeta:
  name: "VAE_1x16x16_4x4x4_biggerbeta"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 16
  latent_resolution_x: 8
  latent_resolution_y: 8

  beta: 0.01
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2

    use_attention: true
    attention_resolutions: []

  training:
    learning_rate: 0.0001


VAE_1x16x16_4x4x4_sigmoid_mse:
  name: "VAE_1x16x16_4x4x4_sigmoid_mse"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 16
  latent_resolution_x: 8
  latent_resolution_y: 8

  beta: 0.001
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2

    use_attention: true
    attention_resolutions: []

  training:
    learning_rate: 0.0001

VAE_1x16x16_4x4x4_funkmoid_mse:
  name: "VAE_1x16x16_4x4x4_funkmoid_mse"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 16
  latent_resolution_x: 8
  latent_resolution_y: 8

  beta: 0.001
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2

    use_attention: true
    attention_resolutions: []

  training:
    learning_rate: 0.0001

VAE_1x16x16_4x4x4_funkmoid2_bce:
  name: "VAE_1x16x16_4x4x4_funkmoid2_bce"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 16
  latent_resolution_x: 8
  latent_resolution_y: 8

  beta: 0.01
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2

    use_attention: true
    attention_resolutions: []

  training:
    learning_rate: 0.0001


VAE_1x16x16_4x4x4_funkmoid2_mse:
  name: "VAE_1x16x16_4x4x4_funkmoid2_mse"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 16
  latent_resolution_x: 4
  latent_resolution_y: 4

  beta: 0.01
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 128
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4

    use_attention: true
    attention_resolutions: []

  training:
    learning_rate: 0.0001

VAE_full_test:
  name: "VAE_full_test"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 64
  data_resolution_y: 64

  latent_num_channels: 8
  latent_resolution_x: 8
  latent_resolution_y: 8

  beta: 0.000001
  
  architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4

    use_attention: true
    attention_resolutions: []

  training:
    learning_rate: 0.0001


VAE_small_test:
  name: "VAE_small_test"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 8
  latent_resolution_x: 4
  latent_resolution_y: 4

  Loss:
    use_discriminator:      True
    discriminator_warm_up:  50
    discriminator_weight:   0.5

    kl_beta: 0.000001

    use_class_weights: True

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001

VAE_perception_test:
  name: "VAE_discriminator_test"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 4
  latent_resolution_x: 4
  latent_resolution_y: 4

  Loss:
    use_discriminator:      false
    discriminator_warm_up:  50
    discriminator_weight:   0.5
    
    use_perceptual_loss:    true
    perceptual_weight:      1.0

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001

VAE_discriminator_test:
  name: "VAE_discriminator_test"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 4
  latent_resolution_x: 8
  latent_resolution_y: 8

  Loss:
    use_discriminator:      false
    discriminator_warm_up:  200
    discriminator_weight:   0.5
    
    use_perceptual_loss:    true
    perceptual_weight:      1.0

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001



VAE_discriminator_perceptual_test:
  name: "VAE_discriminator_perceptual_test"
  description: Test VAE for sanity checks
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 4
  latent_resolution_x: 8
  latent_resolution_y: 8

  Loss:
    use_discriminator:      true
    discriminator_warm_up:  100
    discriminator_weight:   0.5
    
    use_perceptual_loss:    true
    perceptual_weight:      1.0

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001

VAE_Big_test:
  name: VAE_Big_testVAE_Big_test
  description: Trying to get a good vae to work off of here
  
  data_num_channels: 1
  data_resolution_x: 64
  data_resolution_y: 64

  latent_num_channels: 4
  latent_resolution_x: 16
  latent_resolution_y: 16

  Loss:
    use_discriminator:      true
    discriminator_warm_up:  200
    discriminator_weight:   0.5
    
    use_perceptual_loss:    true
    perceptual_weight:      1.0

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001



VAE_Big_test_64:
  name: VAE_Big_test_64
  description: Trying to get a good vae to work off of here
  
  data_num_channels: 1
  data_resolution_x: 64
  data_resolution_y: 64

  latent_num_channels: 4
  latent_resolution_x: 8
  latent_resolution_y: 8

  EMA:
    active: false
    weight: 0.995
    warm_up_steps: 2000

  Loss:
    use_discriminator:      true
    discriminator_warm_up:  150
    discriminator_weight:   0.5
    
    use_perceptual_loss:    true
    perceptual_weight:      1.0
    perceptual_net:         vgg

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001

VAE_EMA_test:
  name: VAE_EMA_test
  description: Trying to get a good vae to work off of here
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 4
  latent_resolution_x: 8
  latent_resolution_y: 8

  EMA:
    active: true
    weight: 0.995
    warm_up_steps: 2000

  Loss:
    use_discriminator:      true
    discriminator_warm_up:  50
    discriminator_weight:   0.5
        
    use_perceptual_loss:    true
    perceptual_weight:      1.0
    perceptual_net:         alex

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001

VAE_EMA_test_new_attention:
  name: VAE_EMA_test_new_attention
  description: Trying to get a good vae to work off of here
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 4
  latent_resolution_x: 8
  latent_resolution_y: 8

  EMA:
    active: true
    weight: 0.995
    warm_up_steps: 2000

  Loss:
    use_discriminator:      true
    discriminator_warm_up:  20
    discriminator_weight:   0.5
        
    use_perceptual_loss:    true
    perceptual_weight:      1.0
    perceptual_net:         alex

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001

VAE_EMA_test_Laplace:
  name: VAE_EMA_test_Laplace
  description: Trying to get a good vae to work off of here

  log_image_interval: 1000
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 4
  latent_resolution_x: 8
  latent_resolution_y: 8

  EMA:
    active: true
    weight: 0.995
    warm_up_steps: 2000

  Loss:
    use_discriminator:      true
    discriminator_warm_up:  20
    discriminator_weight:   0.5
        
    use_perceptual_loss:    true
    perceptual_weight:      1.0
    perceptual_net:         alex

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001


VAE_test_just_like_sd:
  name: VAE_test_just_like_sd
  description: Trying to get a good vae to work off of here

  log_image_interval: 1000
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 8
  latent_resolution_x: 8
  latent_resolution_y: 8

  EMA:
    active: true
    weight: 0.995
    warm_up_steps: 2000

  Loss:
    use_discriminator:      true
    discriminator_warm_up:  50000
    discriminator_weight:   0.5
    discriminator_layers:   2

        
    use_perceptual_loss:    true
    perceptual_weight:      1.0
    perceptual_net:         vgg

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001

VAE_test_just_like_sd_mnist:
  name: VAE_test_just_like_sd_mnist
  description: Trying to get a good vae to work off of here

  log_image_interval: 1000
  
  data_num_channels: 1
  data_resolution_x: 32
  data_resolution_y: 32

  latent_num_channels: 4
  latent_resolution_x: 8
  latent_resolution_y: 8

  EMA:
    active: true
    weight: 0.995
    warm_up_steps: 2000

  Loss:
    use_discriminator:      true
    discriminator_warm_up:  5000
    discriminator_weight:   0.5
    discriminator_layers:   2
        
    use_perceptual_loss:    true
    perceptual_weight:      1.0
    perceptual_net:         vgg

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 64
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001

VAE_1x256x256_4x32x32:
  name: VAE_1x256x256_4x32x32
  description: Trying to get a good vae to work off of here

  log_image_interval: 1000
  
  data_num_channels: 1
  data_resolution_x: 256
  data_resolution_y: 256

  latent_num_channels: 4
  latent_resolution_x: 32
  latent_resolution_y: 32

  EMA:
    active: true
    weight: 0.995
    warm_up_steps: 2000

  Loss:
    use_discriminator:      true
    discriminator_warm_up:  50000
    discriminator_weight:   0.5
    discriminator_layers:   3
        
    use_perceptual_loss:    true
    perceptual_weight:      1.0
    perceptual_net:         vgg

    kl_beta: 0.000001

    use_class_weights: false

  Architecture:
    ResNet_blocks_per_layer: 2
    starting_channels: 128
    dropout: 0.0
    non_linearity: SiLU
    channel_multipliers:
    - 1
    - 2
    - 4
    
    use_attention: true
    attention_resolutions: []

  Training:
    learning_rate: 0.0001






